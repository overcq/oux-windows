//-*-C-*-
//******************************************************************************
// Programista "oux” rozumie nastêpuj¹ce zagadnienia podstawowe:
// ? prze³¹czanie ‹zadañ› wykonywane w pêtli dla kolejnych obudzonych jako ograniczon¹ liniowym czasem aktywacjê kolejnych warstw wykonawczej sieci informacyjnej (jak biologicznej sieci neuronowo-biochemicznej, inaczej elektryczno-molekularnej, inaczej synaptyczno-organicznej)
// ? informacyjno-wykonawcz¹ nienazywaj¹c¹ stwórczoœæ bytow¹ (molekularn¹) w postaci bezwarunkowej pêtli programowej odpowiednio u¿ytej
// ? pe³n¹ dynamicznoœæ systemu ‘uidów’ ‹raportów›/‹impulsatorów›, która jest odrêbna od u¿ywanego systemu zapewniania unikalnoœci ‘idów’ zarejestrowanych ‹raportów›/‹impulsatorów› u¿ywanych pomiêdzy ‹zadaniami›— jak rzeczywistoœæ wykonawcza nie jest zale¿na od nazw, ale zosta³a oparta na statycznych nazwach, bo tutaj program jest kompilowany ca³oœciowo, wiêc nie potrzeba uzgadniaæ ‘uidu’ ‹raportu›/‹impulsatora›
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
// Przeprojektowywane pod rzeczywiste potrzeby.
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
// [ta linia– do aktualizacji.] Instrukcje mog¹ce prze³¹czyæ ‹zadanie›: “X_B”, [“X_E”], “Y_B”, “I_B”. “D_M” i “D_W” zawsze prze³¹czaj¹ jakby proceduralnie do ‹zadania› uruchamianego/zwalnianego, wykonuj¹ blok startowy/koñcowy i wracaj¹, wiêc nie zaliczaj¹ siê do tego zbioru.
// Bloki startowe i koñcowe ‹zadañ› s³u¿¹ obowi¹zkowo do rejestracji (np. ‹raportów›) i zwalniania zasobów ‘interfejsu’ bytu ‹zadania› ·bezwarunkowo· widzianych przez inne. W blokach tych nie wolno prze³¹czaæ (tzn. jawnie, nie przez normalne wykonywanie siê “D_W”) ani wykonywaæ celu ‹zadania›. (Jeœli w bloku startowym zostanie u¿yta jedna z instrukcji prze³¹czenia, to ‹zadanie› pozostanie zablokowane dla ‘schedulera’ w nie wznawialnym (nie obs³ugiwanym) stanie oczekiwania (“E_flow_Z_run_state_S_starting_by_task”). Jeœli zostanie u¿yta w bloku koñcowym, to ‹zadanie› zostanie zablokowane (“E_flow_Z_run_state_S_stopping_by_task”) i usuniête przez ‹zadanie› usuwaj¹ce, po prze³¹czeniu do niego przez ‘schedulera’— bez wykonania reszty programu ‹zadania› usuwanego.)
// Adresy danych dostêpnych przez identyfikatory (adresy ‹okien wgl¹du›) musz¹ byæ ponownie odczytane przed u¿yciem po mo¿liwym prze³¹czeniu ‹zadania›.
//------------------------------------------------------------------------------
// Zasad¹ jest, ¿e instrukcje oczekiwania na coœ przez ‹zadanie› odblokowuj¹ je dok³adnie po zaistnieniu tego czegoœ, bez zale¿noœci raportowania zaistnienia czegokolwiek, co ‹zadanie› ma zarejestrowane, ale czeka na to inn¹ instrukcj¹ prze³¹czaj¹c¹ ‹zadanie›. Wiêc oczekiwanie sekwencyjne na ró¿ne rzeczy przez ‹zadanie› jest sytuacj¹ obs³ugiwan¹ (tak jak powy¿ej napisane), aczkolwiek nie polecan¹.
// W³aœcicielem ‹raportu›/‹impulsatora› jest ‹zadanie›, które na niego czeka (rejestracja oczekiwania– “X_M”/“Yi_M”), i tylko to ‹zadanie› mo¿e czekaæ na ten ‹raport›/‹impulsator› (w dowolnej liczbie miejsc wewn¹trz w³asnej procedury); ale w ‘kompilacji’ ‹modu³ów› do “bibliotek” ‹zadanie› w ‹module› “main” —czyli w g³ównym pliku wykonywalnym programu— nie jest generatorem ‘uidu’ ‹raportu›/‹impulsatora›, który emituje któryœ ‹modu³› “biblioteczny”. W³aœcicielem ‚raportów znacznikowych’ —statycznych, nierejestrowanych, pochodz¹cych z “sygna³ów” ‘uniksowych’— jest ‹zadanie› “main” (a procedura), poniewa¿ tylko to ‹zadanie› mo¿e obs³ugiwaæ stany programu uruchomionego przez nie w sk³adnikach, a niektórych ‚raportów znacznikowych’– ‚scheduler’, poniewa¿ tylko on mo¿e zarz¹dzaæ systemowym przep³ywem wykonania i go prze³¹czaæ.
//------------------------------------------------------------------------------
// “process_call”– synchroniczne w przep³ywie pojedynczego ‹zadania›— funkcje ¿¹dane przy u¿yciu ‘uniksowego’ “sygna³u”:
// Tylko jedno ‹zadanie› w programie (‹sterownik› funkcji programu zewnêtrznego) mo¿e implementowaæ ¿¹dania funkcji konkretnego (jednego) programu "oux” uruchomionego w systemie operacyjnym. Obecnie w programie "bis” rozró¿nianie programów jest realizowane przez rozró¿nianie nazw procesów, tzn. nie jest uwzglêdniony przypadek, gdy program "oux” posiada procesy podrzêdne. [To zdanie sprawdziæ, bo coœ ju¿ by³o zrobione.] Ponadto nie zosta³o (dla optymalizacji) zaimplementowane rozpoznawanie programu typu "oux” (uzupe³niæ o autoryzacjê potwierdzan¹ chwilowo?) oraz w³asnego (wykluczaæ u Ÿród³a), a wykonanie ¿¹dania funkcji do takiego programu nie jest dozwolone.
//TODO Rozwi¹zaæ inaczej “subid” ‹zadañ› w w¹tku systemowym?
_internal
I _X_var( flow, call_req );
_internal
I _X_var( io, stream_write );
//==============================================================================
enum E_flow_Z_run_state
{ E_flow_Z_run_state_S_ready
, E_flow_Z_run_state_S_waiting_for_report
, E_flow_Z_run_state_S_waiting_for_timer
, E_flow_Z_run_state_S_waiting_for_call_reply
, E_flow_Z_run_state_S_starting_by_task
, E_flow_Z_run_state_S_stopping_by_task
};
struct E_flow_Q_task_Z
{ Pc exe_stack;
  N run_state_time;
  Pc reserved_stack, stack;
  Pc touched_stack;
    #ifdef C_line_report
  Pc proc_name;
    #endif
  I run_state_object;
  N stack_size;
  HANDLE thread_flow_mutex;
  volatile B *thread_switch_back;
  P thread_proc_arg;
  void ( *thread_unblock_proc )(P);
  HANDLE thread;
  enum E_flow_Z_run_state run_state;
  unsigned U_R( type, system_unblock_report )   :1;
};
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
struct E_flow_Q_report_Z
{ N uid;
  N reported_count;
};
struct E_flow_Q_timer_Z
{ N left;
  N period;
  N lost_count;
  N uid;
  I task_to;
};
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
struct E_flow_Q_process_call_srv_Z
{ P shm;
  N process_id;
};
struct E_flow_Q_process_call_cli_Z
{ P shm;
  N process_id;
  int shm_id;
  I task_id;
  unsigned U_R( state, active )         :1;
  unsigned U_R( state, ping )           :1;
  unsigned U_R( state, reply )          :1;
};
//==============================================================================
N
E_flow_Q_task_I_granulation( void
){  if( !E_base_S->E_flow_Q_task_S )
        return 0;
    N granulation_u = E_simple_T_multiply_overflow( E_base_S->E_flow_Z_task_stacks_S_n_pages, E_base_S->E_mem_S_page_size )
    || E_base_S->E_flow_Z_task_stacks_S_n_pages * E_base_S->E_mem_S_page_size > E_simple_Z_n_I_mod_i2( ~0, sizeof(N) * 8 - 3 ) + 1 //CONF
    ? E_simple_Z_n_I_mod_i2( ~0, sizeof(N) * 8 - 3 ) + 1 //CONF
    : E_base_S->E_flow_Z_task_stacks_S_n_pages * E_base_S->E_mem_S_page_size;
    granulation_u /= E_mem_Q_tab_R_n( E_base_S->E_flow_Q_task_S );
    granulation_u = E_simple_Z_n_I_align_down_to_v2( granulation_u, E_base_S->E_mem_S_page_size );
    N ret = 0;
    for_each_out( 0, task_id_, E_base_S->E_flow_Q_task_S, E_mem_Q_tab )
    {   struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, task_id_ );
        if( U_R( task->type, system_unblock_report ))
            continue;
        if( granulation_u < E_base_S->E_mem_S_page_size )
        {   ret--;
            continue;
        }
        if( task->stack_size > granulation_u )
            if( task->stack + task->stack_size - granulation_u <= task->touched_stack )
            {   N subtract = task->stack_size - granulation_u - E_base_S->E_mem_S_page_size;
                if(subtract)
                {   V_( VirtualFree( task->stack, subtract, MEM_DECOMMIT ));
                    task->stack += subtract;
                    task->stack_size -= subtract;
                }
            }else
            {   N subtract = task->touched_stack - E_base_S->E_mem_S_page_size - task->stack;
                if(subtract)
                {   V_( VirtualFree( task->stack, subtract, MEM_DECOMMIT ));
                    task->stack += subtract;
                    task->stack_size -= subtract;
                }
                ret--;
            }
    }
    return ret;
}
I
E_flow_Q_task_M( I *uid
, void (*task_proc)(P)
, P thread_proc_arg
, B task_in_thread_kind
    #ifdef C_line_report
, Pc task_proc_name
    #endif
){  N granulation_u = E_simple_T_multiply_overflow( E_base_S->E_flow_Z_task_stacks_S_n_pages, E_base_S->E_mem_S_page_size )
    || E_base_S->E_flow_Z_task_stacks_S_n_pages * E_base_S->E_mem_S_page_size > E_simple_Z_n_I_mod_i2( ~0, sizeof(N) * 8 - 3 ) + 1
    ? E_simple_Z_n_I_mod_i2( ~0, sizeof(N) * 8 - 3 ) + 1 //CONF
    : E_base_S->E_flow_Z_task_stacks_S_n_pages * E_base_S->E_mem_S_page_size;
    granulation_u /= E_mem_Q_tab_R_n( E_base_S->E_flow_Q_task_S );
    granulation_u = E_simple_Z_n_I_align_down_to_v2( granulation_u, E_base_S->E_mem_S_page_size );
    if( granulation_u < E_base_S->E_mem_S_page_size )
    {   if( thread_proc_arg )
            W( thread_proc_arg );
        GV_(NA); // Late instrumentation error: granulation unit too small because too many tasks in available memory.
        return ~0;
    }
    for_each_out( 0, task_id_, E_base_S->E_flow_Q_task_S, E_mem_Q_tab )
    {   struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, task_id_ );
        if( U_R( task->type, system_unblock_report ))
            continue;
        if( task->stack_size > granulation_u )
            if( task->stack + task->stack_size - granulation_u <= task->touched_stack )
            {   N subtract = task->stack_size - granulation_u - E_base_S->E_mem_S_page_size;
                if(subtract)
                {   V_( VirtualFree( task->stack, subtract, MEM_DECOMMIT ));
                    task->stack += subtract;
                    task->stack_size -= subtract;
                }
            }else
            {   GV_(NDFN); // Late instrumentation error: task stack larger than granulation unit.
                N subtract = task->touched_stack - E_base_S->E_mem_S_page_size - task->stack;
                if(subtract)
                {   V_( VirtualFree( task->stack, subtract, MEM_DECOMMIT ));
                    task->stack += subtract;
                    task->stack_size -= subtract;
                }
            }
    }
    N stack_size = E_base_S->E_mem_S_page_size + granulation_u; // Jedna strona pamiêci “PROT_NONE” na pocz¹tku stosu.
    Pc stack;
    Pc exe_stack;
    N touched_size;
    Pc touched_stack;
    if( !task_in_thread_kind )
    {   V( stack = VirtualAlloc( 0, stack_size, MEM_RESERVE, PAGE_NOACCESS ))
        {   if( thread_proc_arg )
                W( thread_proc_arg );
            return ~0;
        }
        exe_stack = stack + stack_size;
        touched_size = E_base_S->E_mem_S_page_size;
        touched_stack = exe_stack - touched_size;
        V( VirtualAlloc( touched_stack, touched_size, MEM_COMMIT, PAGE_READWRITE ))
        {   V_( VirtualFree( stack, 0, MEM_RELEASE ));
            if( thread_proc_arg )
                W( thread_proc_arg );
            return ~0;
        }
    }
    if( E_base_S->E_flow_Q_task_S_current )
        E_flow_Q_task_I_touch_stack();
    I task_id = E_mem_Q_tab_I_add( E_base_S->E_flow_Q_task_S );
    struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, task_id );
    if( !task_in_thread_kind )
    {   task->reserved_stack = task->stack = stack;
        task->touched_stack = touched_stack;
        task->stack_size = stack_size;
    }
        #ifdef C_line_report
    task->proc_name = task_proc_name;
        #endif
    task->run_state = E_flow_Z_run_state_S_starting_by_task;
    U_R( task->type, system_unblock_report ) = task_in_thread_kind;
    if( task_in_thread_kind )
    {   task->thread_proc_arg = thread_proc_arg;
        HANDLE thread_flow_mutex;
        V( thread_flow_mutex = CreateMutex( 0, FALSE, 0 ))
        {   E_mem_Q_tab_I_remove( E_base_S->E_flow_Q_task_S, task_id );
            V_( VirtualFree( stack, 0, MEM_RELEASE ));
            if( thread_proc_arg )
                W( thread_proc_arg );
            return ~0;
        }
        volatile B *M_( thread_switch_back );
        if( !thread_switch_back )
        {   V_( CloseHandle( thread_flow_mutex ));
            E_mem_Q_tab_I_remove( E_base_S->E_flow_Q_task_S, task_id );
            V_( VirtualFree( stack, 0, MEM_RELEASE ));
            if( thread_proc_arg )
                W( thread_proc_arg );
            return ~0;
        }
        task->thread_flow_mutex = thread_flow_mutex;
        task->thread_switch_back = thread_switch_back;
        *thread_switch_back = no;
        I task_id_ = E_base_S->E_flow_Q_task_S_current;
        E_base_S->E_flow_Q_task_S_current = task_id;
        N thread_id;
        V( task->thread = CreateThread( 0, 0, &E_flow_Q_task_in_thread_I_thread_proc, task_proc, 0, &thread_id ))
        {   E_base_S->E_flow_Q_task_S_current = task_id_;
            W( thread_switch_back );
            V_( CloseHandle( thread_flow_mutex ));
            E_mem_Q_tab_I_remove( E_base_S->E_flow_Q_task_S, task_id );
            V_( VirtualFree( stack, 0, MEM_RELEASE ));
            if( thread_proc_arg )
                W( thread_proc_arg );
            return ~0;
        }
        O{  SwitchToThread();
            V_( WaitForSingleObject( thread_flow_mutex, INFINITE ) == WAIT_OBJECT_0 );
            if( *thread_switch_back )
                break;
            V_( ReleaseMutex( thread_flow_mutex ));
        }
        task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, task_id );
        if( task->run_state != E_flow_Z_run_state_S_ready )
        {   task->run_state = E_flow_Z_run_state_S_stopping_by_task;
            HANDLE thread = task->thread;
            V_( ReleaseMutex( thread_flow_mutex ));
            O{  SwitchToThread();
                N exit_code;
                V_( GetExitCodeThread( thread, &exit_code ));
                if( exit_code != STILL_ACTIVE )
                    break;
            }
            E_base_S->E_flow_Q_task_S_current = task_id_;
            V_( CloseHandle( thread_flow_mutex ));
            E_mem_Q_tab_I_remove( E_base_S->E_flow_Q_task_S, task_id );
            V_( VirtualFree( stack, 0, MEM_RELEASE ));
            if( thread_proc_arg )
                W( thread_proc_arg );
            return ~0;
        }
        *thread_switch_back = no;
        E_base_S->E_flow_Q_task_S_current = task_id_;
        return task_id;
    }
    task->exe_stack = 0;
    task->run_state_object = E_base_S->E_flow_Q_task_S_current;
    P *p = ( P * )exe_stack - 1;
    *p = (P)&E_flow_Q_task_I_stop;
    E_flow_Q_task_I_switch( task_id );
    if( !task->exe_stack ) // W bloku– nowe ‹zadanie›: nic nie zmieniaæ na stosie nale¿¹cym do prze³¹czanego.
    {   __asm__ volatile (
        #if defined( __i386__ ) || defined( __x86_64__ )
            #if defined( __i386__ )
        "\n" "mov   %0,%%esp"
            #else
        "\n" "mov   %0,%%rsp"
            #endif
        "\n" "jmp   *%1"
        //NKN Pozostaje zagwarantowanie, ¿e procedura ‹zadania› nie bêdzie nigdy oczekiwaæ (ze wzglêdu na ‘abi’) niczego tutaj nie zapewnianego przez ‘callera’ (m.in. rezerwacji obszaru na stosie, gdy argumentów i tak nie ma przekazywanych).
        :
        : "r" (p), "r" ( task_proc )
                #if defined( __i386__ )
        : "esp"
            #else
        : "rsp"
            #endif
        #else
#error not implemented
        #endif
        );
        _unreachable;
    }
    *uid = task_id;
    return task_id;
}
// Nie wolno tworzyæ “w¹tku”/‘instancji’ tego samego ‹zadania› w bloku startowym (innej ‘instancji’) tego samego ‹zadania›. Czyli nie wolno tworzyæ w ogóle w takim ‹zadaniu›, poniewa¿ ‹zadania› tworzy siê w bloku startowym.
I
E_flow_Q_task_M_thread( I *uid
, I subid
, void (*task_proc)(P)
, P thread_proc_arg
    #ifdef C_line_report
, Pc task_proc_name
    #endif
){  I uid_start = *uid;
    I id;
    if( !~( id = E_flow_Q_task_M( uid, task_proc, thread_proc_arg, yes
        #ifdef C_line_report
    , task_proc_name
        #endif
    )))
        return ~0;
    struct E_mem_Q_tab_Z **tab_subid;
    if( !~uid_start )
    {   *uid = E_mem_Q_tab_I_add( E_base_S->E_flow_Q_task_S_uid_subid );
        tab_subid = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S_uid_subid, *uid );
        *tab_subid = E_mem_Q_tab_M( sizeof(I), subid + 1 );
        if( !*tab_subid )
        {   E_mem_Q_tab_I_remove( E_base_S->E_flow_Q_task_S_uid_subid, *uid );
            E_flow_Q_task_W( &id );
            return ~0;
        }
    }else
    {   tab_subid = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S_uid_subid, *uid );
        E_mem_Q_tab_I_add_i( E_base_S->E_flow_Q_task_S_uid_subid, subid );
    }
    *( I * )E_mem_Q_tab_R( *tab_subid, subid ) = id;
    return *uid;
}
// Procedura ‹zadañ› w w¹tku systemowym.
_internal
WINAPI N
E_flow_Q_task_in_thread_I_thread_proc( P arg
){  struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    V_( WaitForSingleObject( task->thread_flow_mutex, INFINITE ) == WAIT_OBJECT_0 );
    void (*proc)(P);
    proc = arg;
    proc( task->thread_proc_arg );
    task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    V_( ReleaseMutex( task->thread_flow_mutex ));
    return 0;
}
// ‹Zadanie› wykonuje to przed rozpoczêciêm swojej pêtli; w instrukcji “I_D”.
B
E_flow_Q_task_I_begin( void
){  struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    task->run_state = E_flow_Z_run_state_S_ready;
    if( U_R( task->type, system_unblock_report ))
    {   volatile B *thread_switch_back = task->thread_switch_back;
        *thread_switch_back = yes;
        HANDLE thread_flow_mutex = task->thread_flow_mutex;
        V_( ReleaseMutex( thread_flow_mutex ));
        O{  SwitchToThread();
            V_( WaitForSingleObject( thread_flow_mutex, INFINITE ) == WAIT_OBJECT_0 );
            if( !*thread_switch_back )
                break;
            V_( ReleaseMutex( thread_flow_mutex ));
        }
    }else
        E_flow_Q_task_I_switch( task->run_state_object ); // Powrót do ‹zadania› uruchamiaj¹cego bie¿¹ce.
    task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    return task->run_state == E_flow_Z_run_state_S_stopping_by_task;
}
void
E_flow_Q_task_W( I *uid
){  I id = *uid;
    *uid = ~0;
    struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, id );
    task->run_state = E_flow_Z_run_state_S_stopping_by_task;
    task->run_state_object = E_base_S->E_flow_Q_task_S_current;
    if( U_R( task->type, system_unblock_report ))
    {   if( *task->thread_switch_back )
            task->thread_unblock_proc( task->thread_proc_arg );
        E_base_S->E_flow_Q_task_S_current = id;
        HANDLE thread = task->thread;
        HANDLE thread_flow_mutex = task->thread_flow_mutex;
        V_( ReleaseMutex( thread_flow_mutex ));
        O{  SwitchToThread();
            N exit_code;
            V_( GetExitCodeThread( thread, &exit_code ));
            if( exit_code != STILL_ACTIVE )
                break;
        }
        task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, id );
        E_base_S->E_flow_Q_task_S_current = task->run_state_object;
        V_( CloseHandle( task->thread_flow_mutex ));
        W( task->thread_switch_back );
        if( task->thread_proc_arg )
            W( task->thread_proc_arg );
    }else
    {   E_flow_Q_task_I_switch(id); // Prze³¹cz tylko po to, by ‹zadanie› zwalniane zwolni³o zasoby; równie¿ stosowo, hierarchicznie z powrotem prze³¹czaj¹c przy zwalnianiu ‹zadañ› przez siebie uruchomionych.
        task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, id );
        V_( VirtualFree( task->reserved_stack, 0, MEM_RELEASE ));
    }
    E_flow_Q_task_I_touch_stack();
    E_mem_Q_tab_I_remove( E_base_S->E_flow_Q_task_S, id );
}
void
E_flow_Q_task_W_thread( I *uid
, I subid
){  struct E_mem_Q_tab_Z **tab_subid = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S_uid_subid, *uid );
    I id = *( I * )E_mem_Q_tab_R( *tab_subid, subid );
    if( E_mem_Q_tab_R_n( *tab_subid ) != 1 )
        E_mem_Q_tab_I_remove( *tab_subid, subid );
    else
    {   E_mem_Q_tab_W( *tab_subid );
        *uid = ~0;
    }
    E_flow_Q_task_W(&id);
}
// ‹Zadanie› wykonuje to po wyjœciu z procedury; ma adres powrotu na stosie.
_internal
void
E_flow_Q_task_I_stop( void
){  struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    E_flow_Q_task_I_switch( task->run_state_object ); // Powrót do ‹zadania› zwalniaj¹cego bie¿¹ce.
    _unreachable;
}
//------------------------------------------------------------------------------
// Wymuszenie ‘prealokacji’ “stosu” ‹zadania›, by nie zosta³a wywo³ana procedura obs³ugi “sygna³u” ‘uniksowego’ “SEGV” w trakcie zmieniania pamiêci ‘alokowanej’ dynamicznie, z której korzysta.
_internal
void
E_flow_Q_task_I_touch_stack( void
){  if( !E_base_S->E_flow_Q_task_S_current ) // ‹Zadanie› inne ni¿ “main”, poniewa¿ to ma stos zarz¹dzany przez system operacyjny.
        return;
    N pages = 4; //CONF
    if( !pages )
    {   GV_(NDFN); _V();
    }
    volatile Pc sp;
    __asm__ volatile (
    #if defined( __i386__ ) || defined( __x86_64__ )
        #if defined( __i386__ )
    "\n" "mov   %%esp,%0"
        #else
    "\n" "mov   %%rsp,%0"
        #endif
    #else
#error not implemented
    #endif
    : "=r" (sp)
    );
    // Dlatego kolejno “strony” pamiêci, poniewa¿ jest tylko jedna zabezpieczaj¹ca na dole “stosu” ‹zadania›.
    while( pages-- )
    {   sp -= E_base_S->E_mem_S_page_size;
        *sp = 0;
    }
}
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
I
E_flow_Q_report_M( N uid
){  struct E_flow_Q_report_Z *report;
    for_each( report_id, E_base_S->E_flow_Q_report_S, E_mem_Q_tab )
    {   report = E_mem_Q_tab_R( E_base_S->E_flow_Q_report_S, report_id );
        if( report->uid == uid )
            break;
    }
    if( !~report_id )
    {   report_id = E_mem_Q_tab_I_add( E_base_S->E_flow_Q_report_S );
        report = E_mem_Q_tab_R( E_base_S->E_flow_Q_report_S, report_id );
        report->uid = uid;
        report->reported_count = 0;
    }
    return report_id;
}
void
E_flow_Q_report_W( I id
){  E_mem_Q_tab_I_remove( E_base_S->E_flow_Q_report_S, id );
}
//------------------------------------------------------------------------------
void
E_flow_Q_report_I_signal( I id
){  struct E_flow_Q_report_Z *report = E_mem_Q_tab_R( E_base_S->E_flow_Q_report_S, id );
    if( ~report->reported_count )
        report->reported_count++;
    for_each( task_id, E_base_S->E_flow_Q_task_S, E_mem_Q_tab )
    {   struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, task_id );
        if( task->run_state == E_flow_Z_run_state_S_waiting_for_report
        && task->run_state_object == id
        )
        {   task->run_state = E_flow_Z_run_state_S_ready;
            break;
        }
    }
}
B
E_flow_Q_report_I_wait( I id
, N *lost_count
){  B ret;
    struct E_flow_Q_report_Z *report = E_mem_Q_tab_R( E_base_S->E_flow_Q_report_S, id );
    if( report->reported_count )
    {   //for_each( task_id, E_base_S->E_flow_Q_task_S, E_mem_Q_tab )
        //{   struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, task_id );
            //if( task->run_state == E_flow_Z_run_state_S_emiting_report
            //&& task->run_state_object == id
            //)
                //task->run_state = E_flow_Z_run_state_S_ready;
        //}
        ret = no; // Nie wywo³uje “schedule”, poniewa¿ w prze³¹czanym tylko w oznaczonych punktach przep³ywie wykonania— bie¿¹ce ‹zadanie› mog³o umo¿liwiæ zaistnienie ‹raportu›, na który czeka, tylko wtedy, jeœli prze³¹cza do innych ‹zadañ› ·w innych punktach ni¿ to oczekiwanie na ‹raport›·, wiêc po co czekaæ, skoro nie zaburza cyklu prze³¹czania ‹zadañ›, a tylko w implementacji w³asnego ‹zadania› zmienia na z³o¿on¹ (przesuniêt¹) sekwencjê prze³¹czania.
    }else
    {   struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
        task->run_state = E_flow_Z_run_state_S_waiting_for_report;
        task->run_state_object = id;
        ret = E_flow_Q_task_I_schedule();
        report = E_mem_Q_tab_R( E_base_S->E_flow_Q_report_S, id );
    }
    if( lost_count )
        *lost_count = report->reported_count - 1;
    report->reported_count = 0;
    return ret;
}
void
E_flow_Q_report_I_clear( I id
){  struct E_flow_Q_report_Z *report = E_mem_Q_tab_R( E_base_S->E_flow_Q_report_S, id );
    report->reported_count = 0;
}
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
I
E_flow_Q_timer_M( N period
){  if( (S)period < 0 )
    {   GV_(NA); _V();
    }
    N t = GetTickCount();
    I timer_id = E_mem_Q_tab_I_add( E_base_S->E_flow_Q_timer_S );
    struct E_flow_Q_timer_Z *timer = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, timer_id );
    timer->period = period;
    timer->lost_count = 0;
    timer->uid = ~0;
    timer->task_to = E_base_S->E_flow_Q_task_S_current;
    if( E_mem_Q_tab_R_n( E_base_S->E_flow_Q_timer_S ) != 1 )
    {   for_each_out( timer_id, timer_id_, E_base_S->E_flow_Q_timer_S, E_mem_Q_tab )
        {   struct E_flow_Q_timer_Z *timer_ = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, timer_id_ );
            if( timer_->period // Jest co najmniej jeden ‹cykler›.
            || timer_->left // Jest co najmniej jeden wzbudzony ‹impulsator›.
            )
            {   t += timer->period;
                if( (S)( E_base_S->E_flow_Q_timer_S_next_real_time - t ) > 0 )
                    E_base_S->E_flow_Q_timer_S_next_real_time = t;
                timer->left = t - E_base_S->E_flow_Q_timer_S_last_real_time;
                return timer_id;
            }
        }
    }
    E_base_S->E_flow_Q_timer_S_last_real_time = t;
    E_base_S->E_flow_Q_timer_S_next_real_time = t + timer->period;
    timer->left = timer->period;
    return timer_id;
}
void
E_flow_Q_timer_W( I id
){  E_mem_Q_tab_I_remove( E_base_S->E_flow_Q_timer_S, id );
    for_each( timer_id, E_base_S->E_flow_Q_timer_S, E_mem_Q_tab )
    {   struct E_flow_Q_timer_Z *timer = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, timer_id );
        if( timer->period
        || timer->left
        )
            return;
    }
    E_base_S->E_flow_Q_timer_S_next_real_time = ~0;
}
//------------------------------------------------------------------------------
B
E_flow_Q_timer_I_wait( I id
, N *lost_count
){  struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    task->run_state = E_flow_Z_run_state_S_waiting_for_timer;
    task->run_state_object = id;
    B ret = E_flow_Q_task_I_schedule();
    struct E_flow_Q_timer_Z *timer = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, id );
    if( lost_count )
        *lost_count = timer->lost_count;
    timer->lost_count = 0;
    return ret;
}
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
I
E_flow_Q_impulser_M( N uid
){  struct E_flow_Q_timer_Z *timer;
    for_each( timer_id, E_base_S->E_flow_Q_timer_S, E_mem_Q_tab )
    {   timer = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, timer_id );
        if( timer->uid == uid )
            break;
    }
    if( !~timer_id )
    {   timer_id = E_mem_Q_tab_I_add( E_base_S->E_flow_Q_timer_S );
        timer = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, timer_id );
        timer->left = 0;
        timer->period = 0;
        timer->uid = uid;
    }
    timer->task_to = E_base_S->E_flow_Q_task_S_current;
    return timer_id;
}
I
E_flow_Q_impulser_M_srv( N uid
){  struct E_flow_Q_timer_Z *timer;
    for_each( timer_id, E_base_S->E_flow_Q_timer_S, E_mem_Q_tab )
    {   timer = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, timer_id );
        if( timer->uid == uid )
            break;
    }
    if( !~timer_id )
    {   timer_id = E_mem_Q_tab_I_add( E_base_S->E_flow_Q_timer_S );
        timer = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, timer_id );
        timer->left = 0;
        timer->period = 0;
        timer->uid = uid;
    }
    return timer_id;
}
//------------------------------------------------------------------------------
void
E_flow_Q_impulser_I_activate( I id
, N time
){  if( (S)time < 0 )
    {   GV_(NA); _V();
    }
    N t = GetTickCount();
    struct E_flow_Q_timer_Z *timer = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, id );
    timer->left = time;
    if( E_mem_Q_tab_R_n( E_base_S->E_flow_Q_timer_S ) != 1 )
    {   for_each_out( id, timer_id_, E_base_S->E_flow_Q_timer_S, E_mem_Q_tab )
        {   struct E_flow_Q_timer_Z *timer_ = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, timer_id_ );
            if( timer_->period
            || timer_->left
            )
            {   t += timer->left;
                if( (S)( E_base_S->E_flow_Q_timer_S_next_real_time - t ) > 0 )
                    E_base_S->E_flow_Q_timer_S_next_real_time = t;
                timer->left = t - E_base_S->E_flow_Q_timer_S_last_real_time;
                return;
            }
        }
    }
    E_base_S->E_flow_Q_timer_S_last_real_time = t;
    E_base_S->E_flow_Q_timer_S_next_real_time = t + timer->left;
}
void
E_flow_Q_impulser_I_deactivate( I id
){  struct E_flow_Q_timer_Z *timer = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, id );
    if( !timer->left )
        return;
    timer->left = 0;
    for_each_out( id, timer_id_, E_base_S->E_flow_Q_timer_S, E_mem_Q_tab )
    {   struct E_flow_Q_timer_Z *timer_ = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, timer_id_ );
        if( timer_->period
        || timer_->left
        )
            return;
    }
    E_base_S->E_flow_Q_timer_S_next_real_time = ~0;
}
//------------------------------------------------------------------------------
//NDFN Dodaæ “lost_count”?
B
E_flow_Q_impulser_I_wait( I id
){  struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    task->run_state = E_flow_Z_run_state_S_waiting_for_timer;
    task->run_state_object = id;
    return E_flow_Q_task_I_schedule();
}
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
void
E_flow_Q_thread_system_unblock_report_M( void ( *thread_unblock_proc )(P)
, HANDLE *thread_flow_mutex
, volatile B **thread_switch_back
){  struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    task->thread_unblock_proc = thread_unblock_proc;
    *thread_flow_mutex = task->thread_flow_mutex;
    *thread_switch_back = task->thread_switch_back;
}
void
E_flow_Q_thread_system_unblock_report_I_before_block(
  HANDLE thread_flow_mutex
){  E_flow_Q_task_I_touch_stack();
    V_( ReleaseMutex( thread_flow_mutex ));
}
B
E_flow_Q_thread_system_unblock_report_I_after_block(
  HANDLE thread_flow_mutex
){  struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, 0 );
    V_( SetEvent( E_base_S->E_flow_S_resume ));
    V_( WaitForSingleObject( thread_flow_mutex, INFINITE ) == WAIT_OBJECT_0 );
    task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    return task->run_state == E_flow_Z_run_state_S_stopping_by_task;
}
void
E_flow_Q_thread_system_unblock_report_I_unblock( I task_uid
, I task_subid
){  struct E_mem_Q_tab_Z **tab_subid = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S_uid_subid, task_uid );
    struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, *( I * )E_mem_Q_tab_R( *tab_subid, task_subid ));
    task->thread_unblock_proc( task->thread_proc_arg );
}
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
// Ka¿de ‹zadanie› po wywo³aniu “E_flow_Q_task_I_schedule” i po prze³¹czeniu w tej procedurze do innego ‹zadania› (“E_flow_Q_task_I_switch”) czeka przed instrukcj¹ powrotu z tej procedury, by kontynuowaæ w miejscu wywo³ania i ewentualnie zakoñczyæ w³asne ‹zadanie› po powrocie.
__attribute__ ((__noinline__,__returns_twice__,__hot__))
B
E_flow_Q_task_I_schedule( void
){  _forced_statement;
    I schedule_task_id = E_base_S->E_flow_Q_task_S_current;
Loop:
    O{  if( U_E( E_base_S->E_flow_S_signal, exit ))
        {
                #ifdef C_middle_code
            U_F( E_base_S->E_flow_S_signal, exit_all );
                #endif
            struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, 0 );
            task->run_state = E_flow_Z_run_state_S_stopping_by_task;
            if( E_base_S->E_flow_Q_task_S_current != schedule_task_id )
                E_base_S->E_flow_Q_task_S_current = schedule_task_id;
            if( E_base_S->E_flow_Q_task_S_current )
            {   E_flow_Q_task_I_switch(0);
                task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
                return task->run_state == E_flow_Z_run_state_S_stopping_by_task;
            }
            return yes;
        }
/*        if( U_E( E_base_S->E_flow_S_signal, call_req ))
            X_F( flow, call_req );
        if( U_E( E_base_S->E_flow_S_signal, io_ready ))
            X_F( io, stream_write );*/
        N next_real_time = ~0;
        N t = GetTickCount();
        for_each( call_id, E_base_S->E_flow_Q_process_call_cli_S, E_mem_Q_tab )
        {   struct E_flow_Q_process_call_cli_Z *call = E_mem_Q_tab_R( E_base_S->E_flow_Q_process_call_cli_S, call_id );
            if( !U_R( call->state, active ))
                continue;
            struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, call->task_id );
            if( (S)( task->run_state_time - t ) > 0 )
            {   if( (S)( next_real_time - task->run_state_time ) > 0 )
                    next_real_time = task->run_state_time;
            }else if( U_R( call->state, ping ))
            {   task->run_state = E_flow_Z_run_state_S_ready;
                U_L( call->state, active );
            }else
            {   U_F( call->state, ping );
/*                if( kill( call->process_id, SIGVTALRM ))
                {   task->run_state = E_flow_Z_run_state_S_ready;
                    U_L( call->state, active );
                }else
                {   task->run_state_time = t + E_base_S->E_flow_Q_process_call_S_ping_period;
                    if( (S)( next_real_time - task->run_state_time ) > 0 )
                        next_real_time = task->run_state_time;
                }*/
            }
        }
        if( (S)( t - E_base_S->E_flow_Q_timer_S_next_real_time ) >= 0 ) // Czy trzeba uaktualniæ kolejne czasy ‹cyklerów›.
        {   N elapsed_time = t - E_base_S->E_flow_Q_timer_S_last_real_time;
            //NDFN Uzupe³niæ o jakieœ przewidywanie ‘overhead’ na podstawie poprzedniego, by wyeliminowaæ mo¿liwoœæ powtarzania pêtli w pesymistycznym przypadku dla ka¿dego ‹cyklera›? Ale obliczaæ ten czas tylko wtedy, je¿eli ten fragment nie bêdzie móg³ byæ wyw³aszczony z wykonywania w czasie rzeczywistym (wszystkie przerwania wy³¹czone).
            O{  B some_timer_is_active = no, some_timer_has_deactivated = no;
                B some_task_got_ready = no;
                N suspend_time = ~0;
                for_each( timer_id, E_base_S->E_flow_Q_timer_S, E_mem_Q_tab )
                {   struct E_flow_Q_timer_Z *timer = E_mem_Q_tab_R( E_base_S->E_flow_Q_timer_S, timer_id );
                    if( timer->period ) // ‹cykler›.
                    {   if( (S)( elapsed_time - timer->left ) >= 0 ) // ‹cykler› wykona³ obieg— ‹zadanie› do wznowienia.
                        {   N overlate_time = elapsed_time - timer->left;
                            if( (S)( overlate_time - timer->period ) >= 0 ) // ‹cykler› wykona³ wiêcej ni¿ jeden obieg.
                            {   timer->lost_count += overlate_time / timer->period;
                                overlate_time %= timer->period;
                                GV_(NA); Gd( timer->lost_count ); Gd( timer->period ); Gd( overlate_time ); // lost time.
                            }
                            timer->left = timer->period - overlate_time;
                            struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, timer->task_to );
                            if( task->run_state == E_flow_Z_run_state_S_waiting_for_timer
                            && task->run_state_object == timer_id
                            )
                            {   task->run_state = E_flow_Z_run_state_S_ready;
                                some_task_got_ready = yes;
                            }else
                                timer->lost_count++;
                        }else
                            timer->left= timer->left - elapsed_time;
                        if( (S)( suspend_time - timer->left ) > 0 )
                        {   suspend_time = timer->left;
                            some_timer_is_active = yes;
                        }
                    }else if( timer->left ) // Aktywowany ‹impulsator›.
                    {   if( (S)( elapsed_time - timer->left ) >= 0 )
                        {   timer->left = 0;
                            struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, timer->task_to );
                            if( task->run_state == E_flow_Z_run_state_S_waiting_for_timer
                            && task->run_state_object == timer_id
                            )
                            {   task->run_state = E_flow_Z_run_state_S_ready;
                                some_task_got_ready = yes;
                            } // Na razie – jeœli nie mo¿e wznowiæ ‹zadania›, to gubi impuls.
                            some_timer_has_deactivated = yes;
                        }else
                        {   timer->left -= elapsed_time;
                            if( (S)( suspend_time - timer->left ) > 0 )
                            {   suspend_time = timer->left;
                                some_timer_is_active = yes;
                            }
                        }
                    }
                }
                if( some_timer_has_deactivated
                && !some_timer_is_active
                ){  E_base_S->E_flow_Q_timer_S_next_real_time = ~0;
                    break;
                }
                N t_2 = GetTickCount();
                elapsed_time = t_2 - t;
                if( (S)( suspend_time - elapsed_time ) > 0 // Czy przeliczanie czasów ‹cyklerów› trwa³o krócej ni¿ obliczony czas oczekiwania do pierwszego budz¹cego ‹zadanie›?
                || !some_task_got_ready
                ){  E_base_S->E_flow_Q_timer_S_last_real_time = t;
                    E_base_S->E_flow_Q_timer_S_next_real_time = t + suspend_time;
                    break;
                }
                t = t_2;
                GV_(NA); Gd( suspend_time ); Gd( elapsed_time ); // Timer schedule loop overhead.
            }
        }
        for_each_out( E_base_S->E_flow_Q_task_S_current, task_id, E_base_S->E_flow_Q_task_S, E_mem_Q_tab )
        {   struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, task_id );
            if( U_R( task->type, system_unblock_report ))
            {   volatile B *thread_switch_back = task->thread_switch_back;
                if( !*thread_switch_back )
                {   E_base_S->E_flow_Q_task_S_current = task_id;
                    HANDLE thread_flow_mutex = task->thread_flow_mutex;
                    V_( ReleaseMutex( thread_flow_mutex ));
                    O{  SwitchToThread();
                        V_( WaitForSingleObject( thread_flow_mutex, INFINITE ) == WAIT_OBJECT_0 );
                        if( *thread_switch_back )
                            break;
                        V_( ReleaseMutex( thread_flow_mutex ));
                    }
                    SwitchToThread(); // ¯eby daæ szansê na wykonanie siê “w¹tku” ‹zadania›, z którego prze³¹czono z powrotem — od “Xh_B_” do rzeczywistej procedury systemowej, na której siê blokuje.
                    ResetEvent( E_base_S->E_flow_S_resume ); // “SetEvent” z “Xh_B” jest niepotrzebne, wiêc ‘resetuje’ stan, by nie potrzeba by³o póŸniej wykonaæ ponownej pêtli “schedule” ze wzglêdu na stan “wake”.
                    goto Loop; // Wywo³uje “E_flow_Q_task_I_schedule” w sposób wewnêtrzny, gdy nie mo¿na u¿yæ funkcjonalnoœci “E_flow_Q_task_I_switch”, ale przy pierwszej koniecznoœci prze³¹czenia standardowego bêdzie prze³¹cza³ w trybie ·pominiêcia nie ob³ugiwanych systemowych danych zatrzymywania przep³ywu wykonania z tablicy ‹zadañ›· (pominiêcia ‹zadañ›) przekazanych kolejnych typu “w¹tkowanych” ‹systemowych raportów odblokowuj¹cych› z “cyklicznej kolejki”— na rzecz zwyk³ego ‹zadania› (“schedule_task_id”), które wywo³a³o “schedule”.
                }
            }else
            {   if( task->run_state == E_flow_Z_run_state_S_ready )
                {
                        #ifdef E_flow_C_thread_system_unblock_reports
                    if( E_base_S->E_flow_Q_task_S_current != schedule_task_id )
                        E_base_S->E_flow_Q_task_S_current = schedule_task_id;
                    if( task_id != E_base_S->E_flow_Q_task_S_current )
                        #endif
                    {   E_flow_Q_task_I_switch( task_id );
                        task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
                    }
                    return task->run_state == E_flow_Z_run_state_S_stopping_by_task;
                }
            }
        }
        struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
        if( U_R( task->type, system_unblock_report ))
        {   volatile B *thread_switch_back = task->thread_switch_back;
            if( !*thread_switch_back )
            {   HANDLE thread_flow_mutex = task->thread_flow_mutex;
                V_( ReleaseMutex( thread_flow_mutex ));
                O{  SwitchToThread();
                    V_( WaitForSingleObject( thread_flow_mutex, INFINITE ) == WAIT_OBJECT_0 );
                    if( *thread_switch_back )
                        break;
                    V_( ReleaseMutex( thread_flow_mutex ));
                }
                SwitchToThread();
                V_( ResetEvent( E_base_S->E_flow_S_resume ));
                continue;
            }
        }else
            if( task->run_state == E_flow_Z_run_state_S_ready )
            {   if( E_base_S->E_flow_Q_task_S_current != schedule_task_id )
                    E_base_S->E_flow_Q_task_S_current = schedule_task_id;
                return task->run_state == E_flow_Z_run_state_S_stopping_by_task;
            }
        if( U_R( E_base_S->E_flow_S_signal, exit ))
            continue;
        if( (S)( next_real_time - E_base_S->E_flow_Q_timer_S_next_real_time ) > 0 )
            next_real_time = E_base_S->E_flow_Q_timer_S_next_real_time;
        B U_has_suspend_time = ~next_real_time;
        if( U_has_suspend_time )
            t = GetTickCount();
        if(( !U_has_suspend_time
          || (S)( next_real_time - t ) > 0
          )
        && !U_R( E_base_S->E_flow_S_signal, exit )
        )
            MsgWaitForMultipleObjectsEx( 1, &E_base_S->E_flow_S_resume, FALSE, U_has_suspend_time ? next_real_time - t : INFINITE, QS_ALLEVENTS );
    }
}
// Prze³¹czenie do ‹zadania› przez prze³¹czenie wskaŸnika “stosu” wykonania.
__attribute__ ((__noinline__,__returns_twice__,__hot__))
_internal
void
E_flow_Q_task_I_switch( I task_to_id
){  struct E_flow_Q_task_Z *task_from = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    struct E_flow_Q_task_Z *task_to = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, task_to_id );
    E_base_S->E_flow_Q_task_S_current = task_to_id;
    __asm__ volatile (
    #if defined( __i386__ ) || defined( __x86_64__ )
        #if defined( __i386__ )
    "\n" "mov       %%esp,%0"
    "\n" "test      %1,%1"
//CONF jest ‘cmov’?
            #if 1
    "\n" "cmovne    %1,%%esp"
            #else
    "\n" "jz        0f"
    "\n" "mov       %1,%%esp"
    "\n" "0:"
            #endif
        #else
    "\n" "mov       %%rsp,%0"
    "\n" "cmp       $0,%1"
    "\n" "cmovne    %1,%%rsp"
        #endif
    : "=m" ( task_from->exe_stack )
    : "r" ( task_to->exe_stack )
    : "cc", "memory"
    , "st", "st(1)", "st(2)", "st(3)", "st(4)", "st(5)", "st(6)", "st(7)"
        #ifdef __MMX__
    , "mm0", "mm1", "mm2", "mm3", "mm4", "mm5", "mm6", "mm7"
            #ifdef __SSE__
    , "xmm0", "xmm1", "xmm2", "xmm3", "xmm4", "xmm5", "xmm6", "xmm7"
            #endif
        #endif
        #if defined( __i386__ )
    , "ebx", "ecx", "ebp", "esi", "edi"
        #else
    , "rbx", "rcx", "rbp", "rsi", "rdi"
    , "r8", "r9", "r10", "r11", "r12", "r13", "r14", "r15"
            #ifdef __SSE3__
    , "xmm8", "xmm9", "xmm10", "xmm11", "xmm12", "xmm13", "xmm14", "xmm15"
                #ifdef __AVX__
    , "ymm0", "ymm1", "ymm2", "ymm3", "ymm4", "ymm5", "ymm6", "ymm7", "ymm8", "ymm9", "ymm10", "ymm11", "ymm12", "ymm13", "ymm14", "ymm15"
                #endif
            #endif
        #endif
    #else
#error not implemented
    #endif
    );
}
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
_internal
WINAPI long
E_flow_I_exception_handler( EXCEPTION_POINTERS *ex
){  if( ex->ExceptionRecord->ExceptionCode == EXCEPTION_ACCESS_VIOLATION
    && E_base_S->E_flow_Q_task_S_current
    ){  struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
        if( (Pc)ex->ExceptionRecord->ExceptionInformation[1] < task->touched_stack )
        {   if( (Pc)ex->ExceptionRecord->ExceptionInformation[1] >= task->stack + E_base_S->E_mem_S_page_size )
            {   Pc new_base = E_simple_Z_p_I_align_down_to_v2( ex->ExceptionRecord->ExceptionInformation[1], E_base_S->E_mem_S_page_size );
                V_( VirtualAlloc( new_base
                , task->touched_stack - new_base
                , MEM_COMMIT
                , PAGE_READWRITE
                ));
                task->touched_stack = new_base;
                return EXCEPTION_CONTINUE_EXECUTION;
            }
            if( (Pc)ex->ExceptionRecord->ExceptionInformation[1] >= task->stack )
            {   GV_(NA); // Late instrumentation error: task stack too small.
            }
        }
    }
    GV_(NDFN); Gh( ex->ExceptionRecord->ExceptionCode ); Gh( ex->ExceptionRecord->ExceptionAddress ); // Other fault.
    return E_base_S->E_flow_S_default_exception_filter(ex);
}
//------------------------------------------------------------------------------
_internal
void
E_flow_Z_signal_V_process_call_ping( int uid
){  //V0( kill( siginfo->si_pid, SIGPROF )){}
}
_internal
void
E_flow_Z_signal_V_process_call_pong( int uid
){  for_each( call_id, E_base_S->E_flow_Q_process_call_cli_S, E_mem_Q_tab )
    {   struct E_flow_Q_process_call_cli_Z *call = E_mem_Q_tab_R( E_base_S->E_flow_Q_process_call_cli_S, call_id );
//        if( call->process_id == siginfo->si_pid )
        {   U_L( call->state, ping );
            break;
        }
    }
}
_internal
void
E_flow_Z_signal_V_process_call_req( int uid
){  for_each( call_id, E_base_S->E_flow_Q_process_call_srv_S, E_mem_Q_tab )
    {   struct E_flow_Q_process_call_srv_Z *call = E_mem_Q_tab_R( E_base_S->E_flow_Q_process_call_srv_S, call_id );
/*        if( call->process_id == siginfo->si_pid )
        {   GV_(NXP); Gd( siginfo->si_pid ); // Duplicate process call request.
            return;
        }*/
    }
    P shm;
/*    if( !~(N)( shm = E_mem_Q_shared_Q_blk_M( siginfo->si_value.sival_int )))
        return;*/
    call_id = E_mem_Q_tab_I_add( E_base_S->E_flow_Q_process_call_srv_S );
    struct E_flow_Q_process_call_srv_Z *call = E_mem_Q_tab_R( E_base_S->E_flow_Q_process_call_srv_S, call_id );
//    call->process_id = siginfo->si_pid;
    call->shm = shm;
}
_internal
void
E_flow_Z_signal_V_process_call_reply( int uid
){  for_each( call_id, E_base_S->E_flow_Q_process_call_cli_S, E_mem_Q_tab )
    {   struct E_flow_Q_process_call_cli_Z *call = E_mem_Q_tab_R( E_base_S->E_flow_Q_process_call_cli_S, call_id );
//        if( call->process_id == siginfo->si_pid )
        {   U_L( call->state, active );
            U_L( call->state, ping );
            struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, call->task_id );
            task->run_state = E_flow_Z_run_state_S_ready;
            return;
        }
    }
//    GV_(NXP); Gd( siginfo->si_pid ); // Call reply from a unrequested process.
}
//~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
I
E_flow_Q_process_call_M( N l
, P *data
){  N shm_id;
/*    if( !~( shm_id = E_mem_Q_shared_M(l)))
        return ~0;*/
    P shm;
/*    if( !~(N)( shm = E_mem_Q_shared_Q_blk_M( shm_id )))
    {   E_mem_Q_shared_W( shm_id );
        return ~0;
    }*/
    I call_id = E_mem_Q_tab_I_add( E_base_S->E_flow_Q_process_call_cli_S );
    struct E_flow_Q_process_call_cli_Z *call = E_mem_Q_tab_R( E_base_S->E_flow_Q_process_call_cli_S, call_id );
    U_L( call->state, active );
    call->shm_id = shm_id;
    call->shm = shm;
    *data = shm;
    return call_id;
}
void
E_flow_Q_process_call_W( I id
){  struct E_flow_Q_process_call_cli_Z *call = E_mem_Q_tab_R( E_base_S->E_flow_Q_process_call_cli_S, id );
/*    E_mem_Q_shared_Q_blk_W( call->shm );
    E_mem_Q_shared_W( call->shm_id );*/
    E_mem_Q_tab_I_remove( E_base_S->E_flow_Q_process_call_cli_S, id );
}
//------------------------------------------------------------------------------
B
E_flow_Q_process_call_I( I id
, N process_id
, B *successful
){  J_assert( process_id > 0 );
    struct E_flow_Q_process_call_cli_Z *call = E_mem_Q_tab_R( E_base_S->E_flow_Q_process_call_cli_S, id );
    call->task_id = E_base_S->E_flow_Q_task_S_current;
    call->process_id = process_id;
    struct E_flow_Q_task_Z *task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    task->run_state = E_flow_Z_run_state_S_waiting_for_call_reply;
    task->run_state_time = GetTickCount() + E_base_S->E_flow_Q_process_call_S_ping_period;
//    union sigval sv;
//    sv.sival_int = call->shm_id;
    U_F( call->state, active );
//    V0( sigqueue( process_id, SIGUSR1, sv ))
    {   U_L( call->state, active );
        *successful = no;
        return no;
    }
    B ret = E_flow_Q_task_I_schedule();
    task = E_mem_Q_tab_R( E_base_S->E_flow_Q_task_S, E_base_S->E_flow_Q_task_S_current );
    *successful = !U_R( call->state, ping );
    return ret;
}
//------------------------------------------------------------------------------
D( flow, call_srv )
{   X_M_( flow, call_req );
    I_D
    {   X_B( flow, call_req, 0 )
            break;
        for_each_pop( call_id, E_base_S->E_flow_Q_process_call_srv_S, E_mem_Q_tab )
        {   struct E_flow_Q_process_call_srv_Z *call = E_mem_Q_tab_R( E_base_S->E_flow_Q_process_call_srv_S, call_id );
/*            E_flow_Q_process_call_I_func( call->shm );
            E_mem_Q_shared_Q_blk_W( call->shm );
            V0( kill( call->process_id, SIGUSR2 )){}*/
        }
    }
    X_W( flow, call_req );
}
//******************************************************************************
